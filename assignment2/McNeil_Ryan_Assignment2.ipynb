{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "id": "ca64beac5c6b6f7e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WD: D:\\School\\2024 Spring\\CSC74020 Machine Learning\\Assignment_2\n",
      "CPU cores: 16\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "#I may change environs between desktop & laptop, so I run the below to check my WD and that multicore processing is still available.\n",
    "print(\"WD:\", os.getcwd())\n",
    "print(\"CPU cores:\", os.cpu_count())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "76c414f391c9ff15",
   "execution_count": 861
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Part A: Model Code and Exploration (100 pts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "id": "7b812f8cb615333f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Perform Exploratory Data Analysis (EDA) and discuss the data and what you observe\n",
    "prior to beginning modeling and how impact how to proceed [10 pts]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "id": "65f8e5f59e8dfd93"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length:  8000\n",
      "Width:  40\n",
      "Variables:  Index(['discharge_disposition_id', 'admission_source_id', 'payer_code',\n",
      "       'medical_specialty', 'num_lab_procedures', 'num_procedures',\n",
      "       'num_medications', 'number_outpatient', 'number_emergency',\n",
      "       'number_diagnoses', 'max_glu_serum', 'metformin', 'repaglinide',\n",
      "       'nateglinide', 'chlorpropamide', 'glimepiride', 'acetohexamide',\n",
      "       'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone',\n",
      "       'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone', 'tolazamide',\n",
      "       'examide', 'citoglipton', 'insulin', 'glyburide.metformin',\n",
      "       'glipizide.metformin', 'glimepiride.pioglitazone',\n",
      "       'metformin.rosiglitazone', 'metformin.pioglitazone', 'change',\n",
      "       'diabetesMed', 'readmitted', '2nd_diag', '3rd_diag', 'ai_response'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": "  discharge_disposition_id       admission_source_id payer_code  \\\n0       Discharged to home  Transfer from a hospital        NaN   \n1       Discharged to home  Transfer from a hospital        NaN   \n2       Discharged to home            Emergency Room         SP   \n3       Discharged to home            Emergency Room        NaN   \n4       Discharged to home        Physician Referral         MD   \n\n  medical_specialty  num_lab_procedures  num_procedures  num_medications  \\\n0               NaN                  24               2               17   \n1               NaN                  37               3               14   \n2  Emergency/Trauma                  60               4               17   \n3               NaN                  40               3               25   \n4   Surgery-General                  31               2               18   \n\n   number_outpatient  number_emergency  number_diagnoses  ...  \\\n0                  0                 0                 8  ...   \n1                  0                 0                 8  ...   \n2                  0                 0                 9  ...   \n3                  1                 0                 9  ...   \n4                  0                 0                 7  ...   \n\n  glipizide.metformin glimepiride.pioglitazone metformin.rosiglitazone  \\\n0                  No                       No                      No   \n1                  No                       No                      No   \n2                  No                       No                      No   \n3                  No                       No                      No   \n4                  No                       No                      No   \n\n  metformin.pioglitazone change diabetesMed readmitted 2nd_diag 3rd_diag  \\\n0                     No     No         Yes      False      414      428   \n1                     No     No         Yes      False      410      414   \n2                     No     No          No       True      537      786   \n3                     No     Ch         Yes       True      425      428   \n4                     No     No         Yes       True      682      998   \n\n                                         ai_response  \n0  Based on the diagnosis code 250.01, which indi...  \n1  Based on the information provided, I recommend...  \n2  Based on the information provided, the patient...  \n3  Based on the information provided, the patient...  \n4  Based on the information provided, the patient...  \n\n[5 rows x 40 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>discharge_disposition_id</th>\n      <th>admission_source_id</th>\n      <th>payer_code</th>\n      <th>medical_specialty</th>\n      <th>num_lab_procedures</th>\n      <th>num_procedures</th>\n      <th>num_medications</th>\n      <th>number_outpatient</th>\n      <th>number_emergency</th>\n      <th>number_diagnoses</th>\n      <th>...</th>\n      <th>glipizide.metformin</th>\n      <th>glimepiride.pioglitazone</th>\n      <th>metformin.rosiglitazone</th>\n      <th>metformin.pioglitazone</th>\n      <th>change</th>\n      <th>diabetesMed</th>\n      <th>readmitted</th>\n      <th>2nd_diag</th>\n      <th>3rd_diag</th>\n      <th>ai_response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Discharged to home</td>\n      <td>Transfer from a hospital</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>24</td>\n      <td>2</td>\n      <td>17</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>...</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>False</td>\n      <td>414</td>\n      <td>428</td>\n      <td>Based on the diagnosis code 250.01, which indi...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Discharged to home</td>\n      <td>Transfer from a hospital</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>37</td>\n      <td>3</td>\n      <td>14</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>...</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>False</td>\n      <td>410</td>\n      <td>414</td>\n      <td>Based on the information provided, I recommend...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Discharged to home</td>\n      <td>Emergency Room</td>\n      <td>SP</td>\n      <td>Emergency/Trauma</td>\n      <td>60</td>\n      <td>4</td>\n      <td>17</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>...</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>True</td>\n      <td>537</td>\n      <td>786</td>\n      <td>Based on the information provided, the patient...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Discharged to home</td>\n      <td>Emergency Room</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>40</td>\n      <td>3</td>\n      <td>25</td>\n      <td>1</td>\n      <td>0</td>\n      <td>9</td>\n      <td>...</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Ch</td>\n      <td>Yes</td>\n      <td>True</td>\n      <td>425</td>\n      <td>428</td>\n      <td>Based on the information provided, the patient...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Discharged to home</td>\n      <td>Physician Referral</td>\n      <td>MD</td>\n      <td>Surgery-General</td>\n      <td>31</td>\n      <td>2</td>\n      <td>18</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n      <td>...</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>True</td>\n      <td>682</td>\n      <td>998</td>\n      <td>Based on the information provided, the patient...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 40 columns</p>\n</div>"
     },
     "execution_count": 862,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_data = pd.read_csv(\"8k_diabetes_train.csv\",\n",
    "                              na_values=\"?\")\n",
    "print(\"Length: \", len(full_train_data))\n",
    "print(\"Width: \", len(full_train_data.columns))\n",
    "print(\"Variables: \", full_train_data.columns)\n",
    "full_train_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "a7641a5809738813",
   "execution_count": 862
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "outputs": [
    {
     "data": {
      "text/plain": "Discharged to home                                                                                             4864\nDischarged/transferred to SNF                                                                                   954\nDischarged/transferred to home with home health service                                                         920\nNaN                                                                                                             364\nExpired                                                                                                         153\nDischarged/transferred to another short term hospital                                                           139\nDischarged/transferred to another rehab fac including rehab units of a hospital.                                134\nDischarged/transferred to another  type of inpatient care institution                                           130\nNot Mapped                                                                                                      107\nDischarged/transferred to ICF                                                                                    80\nDischarged/transferred to a long term care hospital.                                                             39\nLeft AMA                                                                                                         36\nHospice / home                                                                                                   28\nHospice / medical facility                                                                                       22\nDischarged/transferred to home under care of Home IV provider                                                    12\nDischarged/transferred/referred to a psychiatric hospital of a psychiatric distinct part unit of a hospital      11\nDischarged/transferred within this institution to Medicare approved swing bed                                     3\nAdmitted as an inpatient to this hospital                                                                         2\nDischarged/transferred/referred to this institution for outpatient services                                       1\nDischarged/transferred/referred another institution for outpatient services                                       1\nName: discharge_disposition_id, dtype: int64"
     },
     "execution_count": 863,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I investigated value counts for every variable. For brevity, I include only this one example in my final submission.\n",
    "full_train_data.discharge_disposition_id.value_counts(dropna=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "outputs": [
    {
     "data": {
      "text/plain": "MC    1988\nHM     364\nBC     300\nSP     242\nUN     221\nMD     189\nCP     159\nCM      88\nDM      46\nOG      39\nPO      34\nWC       9\nSI       8\nOT       6\nCH       5\nName: payer_code, dtype: int64"
     },
     "execution_count": 864,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_data.payer_code.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For \"Payer Code\" & \"Medical Specialty\", \"?\" is the largest class. I re-wrote my read_csv command to explicitly identify these as NAs. This is a lot of missing data for these columns. Next, I'll look at the distributions of the continuous variables."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "outputs": [
    {
     "data": {
      "text/plain": "count    8000.000000\nmean       43.183375\nstd        19.518187\nmin         1.000000\n25%        32.000000\n50%        44.000000\n75%        57.000000\nmax       120.000000\nName: num_lab_procedures, dtype: float64"
     },
     "execution_count": 865,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I also did the below for all other continuous variables. Those cells have been deleted from the final submission for brevity.\n",
    "full_train_data.num_lab_procedures.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "outputs": [
    {
     "data": {
      "text/plain": "discharge_disposition_id     True\nadmission_source_id          True\npayer_code                   True\nmedical_specialty            True\nnum_lab_procedures          False\nnum_procedures              False\nnum_medications             False\nnumber_outpatient           False\nnumber_emergency            False\nnumber_diagnoses            False\nmax_glu_serum                True\nmetformin                   False\nrepaglinide                 False\nnateglinide                 False\nchlorpropamide              False\nglimepiride                 False\nacetohexamide               False\nglipizide                   False\nglyburide                   False\ntolbutamide                 False\npioglitazone                False\nrosiglitazone               False\nacarbose                    False\nmiglitol                    False\ntroglitazone                False\ntolazamide                  False\nexamide                     False\ncitoglipton                 False\ninsulin                     False\nglyburide.metformin         False\nglipizide.metformin         False\nglimepiride.pioglitazone    False\nmetformin.rosiglitazone     False\nmetformin.pioglitazone      False\nchange                      False\ndiabetesMed                 False\nreadmitted                  False\n2nd_diag                     True\n3rd_diag                     True\nai_response                 False\ndtype: bool"
     },
     "execution_count": 866,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I use the below code to identify which columns have any NAs.\n",
    "pd.isna(full_train_data).max()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have 8000 records of 39 features plus one target feature for readmission. We have a variety of continuous, categorical, and boolean variables, plus one string variable of text called \"ai_response.\" For most of the continuous variables (and several of the others), there appear to be a small but not insignificant number of extreme outliers, I will want to keep this in mind when performing test_train_split and training.\n",
    "\n",
    "Further, we have na values that we will want to somehow deal with in the variables: # Discharge_disposition_id, Admission_source_id, and Max_glu_serum, \"Payer Code\" & \"Medical Specialty\". I may also want to rename \"?\" values to proper NAs before doing so.\n",
    "\n",
    "\"2nd_diag\" and \"3rd_diag\" are unclear. The name, repeated values, occasional letters & decimals all seem to imply diagnosis codes. As such, it may not be reasonable to try to impute the few NAs."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Pre-processed categorical data for use in the model and justified pre-processing\n",
    "method. Note this may be different for each algorithm you try. [10 pts]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "id": "c43475e47ecf0f00"
  },
  {
   "cell_type": "markdown",
   "source": [
    "I address the columns in order, one at a time. First,  \"discharge_disposition_id\".\n",
    "\n",
    "I believe this variable is best left as categorical (rather than ordinal), as there is no clear hierarchy of values. I believe \"Not Mapped\" should be NAs, and I reason that patients who die in care necessarily can't be readmitted, so other data about them may not be useful for predicting readmission. On inspection, I see no reasonable way to impute NAs as any other values.--The AI output seems to agree for many of those patients."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "outputs": [],
   "source": [
    "full_train_data.discharge_disposition_id = full_train_data.discharge_disposition_id.replace(\"Not Mapped\", np.nan)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "outputs": [
    {
     "data": {
      "text/plain": "False    153\nName: readmitted, dtype: int64"
     },
     "execution_count": 868,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I confirm that there are no zombies in our data:\n",
    "full_train_data.loc[(full_train_data['discharge_disposition_id'] == \"Expired\")].readmitted.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index '135' is now named:  136\n",
      "Undropped rows:  0\n"
     ]
    }
   ],
   "source": [
    "# I use the following method for dropping rows because alternative methods can result in missing indices.\n",
    "# This method ensures that I will not encounter missing indices errors later on.\n",
    "indices_to_drop = full_train_data[full_train_data['discharge_disposition_id'] == \"Expired\"].index\n",
    "full_train_data.drop(index=indices_to_drop, inplace=True)\n",
    "#See how the indices are not decremented\n",
    "print(\"Index '135' is now named: \", (full_train_data.iloc[135].name))\n",
    "# Check that rows have been successfully dropped.\n",
    "print(\"Undropped rows: \", len(full_train_data.loc[(full_train_data['discharge_disposition_id'] == \"Expired\")].readmitted.value_counts()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index '135' is now named:  135\n"
     ]
    }
   ],
   "source": [
    "# I correct the index\n",
    "full_train_data.set_index(np.arange(len(full_train_data)), inplace=True)\n",
    "print(\"Index '135' is now named: \", (full_train_data.iloc[135].name))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, admission_source_id. I replace \"Not Mapped\" with NA.\n",
    "Additionally, I do not believe it is possible to impute NAs. The distribution is relatively split across the two most prevalent categories, and there is no way to convert to numeric values."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "outputs": [],
   "source": [
    "full_train_data.admission_source_id.replace(\"Not Mapped\", np.nan, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, payer_code. \"?\" have already been read as NAs by my read_csv command.\n",
    "My intuition for imputing NAs is that \"?\" may be patients who either do not have a way to pay right away, or who cannot pay at all. This may correlate with socioeconomic status, an external variable that may influence readmission. However, I cannot confirm this, and it may be a risk to impute NAs (or designate them their own category) when they represent the bulk of the data. I *try* imputing NAs as their own category, but I may change this later and compare the effect on model performance."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "outputs": [
    {
     "data": {
      "text/plain": "No_code    4229\nMC         1933\nHM          360\nBC          296\nSP          239\nUN          218\nMD          186\nCP          155\nCM           86\nDM           45\nOG           38\nPO           34\nWC            9\nSI            8\nOT            6\nCH            5\nName: payer_code, dtype: int64"
     },
     "execution_count": 872,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_data.payer_code.fillna(\"No_code\", inplace=True)\n",
    "full_train_data.payer_code.value_counts(dropna=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, medical_specialty. I replace obvious NAs. I also do not believe it is possible to simply impute NAs, as the data is categorical and NAs represent a sizable chunk of the data.\n",
    "\n",
    "Given more time, it might be possible to do so using information from the \"ai_response\" column.\n",
    "\n",
    "I do not change any other outliers or 'suspicious' values, as I am unsure if or how they should be recategorized. e.g. \"Surgery-PlasticwithinHeadandNeck\"."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "outputs": [],
   "source": [
    "# Replacing obvious NA values\n",
    "full_train_data.medical_specialty = full_train_data.medical_specialty.replace(\"PhysicianNotFound\", np.nan)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Additionally, I prep medical_specialty for one-hot encoding by setting all but the 10 most common categories to NA. These also happen to be the only categories which each account for more than 1% of the data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "outputs": [],
   "source": [
    "cols_to_keep = (\"InternalMedicine\", \"Family/GeneralPractice\", \"Cardiology\",\"Emergency/Trauma\", \"Surgery-General\", \"Orthopedics-Reconstructive\", \"Nephrology\", \"Psychiatry\", \"Orthopedics\", \"ObstetricsandGynecology\")\n",
    "\n",
    "full_train_data.loc[~full_train_data[\"medical_specialty\"].isin(cols_to_keep), \"medical_specialty\"] = np.nan"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "outputs": [
    {
     "data": {
      "text/plain": "NaN                           3927\nInternalMedicine              1494\nFamily/GeneralPractice         675\nCardiology                     552\nEmergency/Trauma               387\nSurgery-General                269\nOrthopedics-Reconstructive     132\nNephrology                     123\nPsychiatry                     104\nOrthopedics                    101\nObstetricsandGynecology         83\nName: medical_specialty, dtype: int64"
     },
     "execution_count": 875,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_data.medical_specialty.value_counts(dropna=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, max_glu_serum. I would consider this ordinal data, but not interval data, as I cannot confirm that the distance between \"Norm\" and \">200\" is equal to the distance between \">200\" and \">300\". So I will One-Hot encode this variable at the end of this section, instead of label encoding.\n",
    "Assuming these are readings for blood glucose serum test, I'm assuming it is only administered when there is a reasonable chance that the patient's blood glucose might be elevated. As such, I believe I could impute NAs for this column as \"Norm\". However, I wound up making NAs their own category, since information may be gleaned from the fact that a doctor thought administration of a test was necessary, even if blood glucose came back normal."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "outputs": [
    {
     "data": {
      "text/plain": "No_test    7333\nNorm        267\n>200        152\n>300         95\nName: max_glu_serum, dtype: int64"
     },
     "execution_count": 876,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_data.max_glu_serum = full_train_data.max_glu_serum.fillna(\"No_test\")\n",
    "full_train_data.max_glu_serum.value_counts(dropna=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, \"Metformin\" through \"Insulin\" appear to be ordinal, but not interval, same problem as above. I will one-hot encode these later. I drop acetohexamide, troglitazone, examide, and citoglipton because they contain only one value."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metformin : 4\n",
      "repaglinide : 4\n",
      "nateglinide : 4\n",
      "chlorpropamide : 3\n",
      "glimepiride : 4\n",
      "acetohexamide : 1\n",
      "glipizide : 4\n",
      "glyburide : 4\n",
      "tolbutamide : 2\n",
      "pioglitazone : 4\n",
      "rosiglitazone : 4\n",
      "acarbose : 3\n",
      "miglitol : 4\n",
      "troglitazone : 1\n",
      "tolazamide : 2\n",
      "examide : 1\n",
      "citoglipton : 1\n"
     ]
    }
   ],
   "source": [
    "for col in full_train_data.columns[11:28]:\n",
    "    print(col,\":\", len(full_train_data[col].unique()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "outputs": [],
   "source": [
    "full_train_data = full_train_data.drop([\"acetohexamide\",\n",
    "                                        \"troglitazone\",\n",
    "                                        \"examide\",\n",
    "                                        \"citoglipton\"],\n",
    "                                       axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, I drop nateglinide, chlorpropamide, tolbutamide, acarbose, miglitol, and tolazamide, because the \"No\" class represents 99% or more of records. 99% is an arbitrary threshold; realistically, I could probably drop even more of these columns."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metformin :\n",
      " No        6279\n",
      "Steady    1435\n",
      "Up          95\n",
      "Down        38\n",
      "Name: metformin, dtype: int64\n",
      "repaglinide :\n",
      " No        7741\n",
      "Steady      91\n",
      "Up          11\n",
      "Down         4\n",
      "Name: repaglinide, dtype: int64\n",
      "nateglinide :\n",
      " No        7804\n",
      "Steady      41\n",
      "Down         1\n",
      "Up           1\n",
      "Name: nateglinide, dtype: int64\n",
      "chlorpropamide :\n",
      " No        7836\n",
      "Steady      10\n",
      "Up           1\n",
      "Name: chlorpropamide, dtype: int64\n",
      "glimepiride :\n",
      " No        7457\n",
      "Steady     356\n",
      "Up          26\n",
      "Down         8\n",
      "Name: glimepiride, dtype: int64\n",
      "glipizide :\n",
      " No        6800\n",
      "Steady     934\n",
      "Up          74\n",
      "Down        39\n",
      "Name: glipizide, dtype: int64\n",
      "glyburide :\n",
      " No        6920\n",
      "Steady     799\n",
      "Up          80\n",
      "Down        48\n",
      "Name: glyburide, dtype: int64\n",
      "tolbutamide :\n",
      " No        7846\n",
      "Steady       1\n",
      "Name: tolbutamide, dtype: int64\n",
      "pioglitazone :\n",
      " No        7295\n",
      "Steady     525\n",
      "Up          20\n",
      "Down         7\n",
      "Name: pioglitazone, dtype: int64\n",
      "rosiglitazone :\n",
      " No        7247\n",
      "Steady     576\n",
      "Up          17\n",
      "Down         7\n",
      "Name: rosiglitazone, dtype: int64\n",
      "acarbose :\n",
      " No        7822\n",
      "Steady      24\n",
      "Up           1\n",
      "Name: acarbose, dtype: int64\n",
      "miglitol :\n",
      " No        7843\n",
      "Steady       2\n",
      "Up           1\n",
      "Down         1\n",
      "Name: miglitol, dtype: int64\n",
      "tolazamide :\n",
      " No        7843\n",
      "Steady       4\n",
      "Name: tolazamide, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in full_train_data.columns[11:24]:\n",
    "    print(col,\":\\n\", full_train_data[col].value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "outputs": [],
   "source": [
    "full_train_data = full_train_data.drop([\"nateglinide\",\n",
    "                                        \"chlorpropamide\",\n",
    "                                        \"tolbutamide\",\n",
    "                                        \"acarbose\",\n",
    "                                        \"miglitol\",\n",
    "                                        \"tolazamide\"],\n",
    "                                       axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, I drop \"glyburide.metformin\" and \"glipizide.metformin\" because nearly all values are \"no\", and I drop \"glimepiride.pioglitazone\" through \"metformin.pioglitazone\" because they *only* contain \"no\" values.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai_response : 6802\n"
     ]
    }
   ],
   "source": [
    "#Print number of unique values\n",
    "for col in full_train_data.columns[29:34]:\n",
    "    print(col,\":\", len(full_train_data[col].unique()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "outputs": [
    {
     "data": {
      "text/plain": "No        7803\nSteady      42\nDown         1\nUp           1\nName: glyburide.metformin, dtype: int64"
     },
     "execution_count": 882,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(full_train_data[\"glyburide.metformin\"])\n",
    "# 99.43% of the data is \"no\"."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "outputs": [
    {
     "data": {
      "text/plain": "No        7845\nSteady       2\nName: glipizide.metformin, dtype: int64"
     },
     "execution_count": 883,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(full_train_data[\"glipizide.metformin\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "outputs": [],
   "source": [
    "full_train_data = full_train_data.drop([\"glyburide.metformin\",\n",
    "                                        \"glipizide.metformin\",\n",
    "                                        \"glimepiride.pioglitazone\",\n",
    "                                        \"metformin.rosiglitazone\",\n",
    "                                        \"metformin.pioglitazone\"],\n",
    "                                       axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\"change\", \"diabetes_med\" and \"readmitted\" I encode as a binary. This is both to ensure it reads as a 0-1 or true-false to my model(s), and for interpretability."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "outputs": [],
   "source": [
    "full_train_data.change = full_train_data.change.replace(\"Ch\", 1)\n",
    "full_train_data.change = full_train_data.change.replace(\"No\", 0)\n",
    "\n",
    "full_train_data.diabetesMed = full_train_data.diabetesMed.replace(\"Yes\", 1)\n",
    "full_train_data.diabetesMed = full_train_data.diabetesMed.replace(\"No\", 0)\n",
    "\n",
    "full_train_data.readmitted = full_train_data.readmitted.replace(True, 1)\n",
    "full_train_data.readmitted = full_train_data.readmitted.replace(False, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\"2nd_diag\" and \"3rd_diag\". As stated above, I believe these may be diagnosis codes. As such, I can't impute NAs and I consider them as categorical. Below I ensure these columns are set as strings, rather than floats."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "outputs": [],
   "source": [
    "full_train_data[\"2nd_diag\"] = full_train_data[\"2nd_diag\"].astype(str)\n",
    "full_train_data[\"3rd_diag\"] = full_train_data[\"3rd_diag\"].astype(str)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "outputs": [],
   "source": [
    "# It is not possible for a column to have more than one datatype. I re-confirm that my index has been set correctly (by the absense of errors) and no glitches have occurred in type processing.\n",
    "for j in (\"2nd_diag\", \"3rd_diag\"):\n",
    "    for i in np.arange(len(full_train_data)):\n",
    "        if type(full_train_data[j][i]) != str:\n",
    "            print(type(full_train_data[j][i]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "My biggest lingering concern is how to encode these categorical variables. On one hand, multi-label encoding may cause my models to misinterpret categorical data as having an ordered, ratio relationship; on the other, one-hot encoding would explode the number of columns given the number of categories and categorical variables I have, possibly leading to high-dimensionality problems. For simplicity, I will one-hot encode columns with <100 categoires."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discharge_disposition_id : 18\n",
      "admission_source_id : 10\n",
      "payer_code : 16\n",
      "medical_specialty : 11\n",
      "max_glu_serum : 4\n",
      "metformin : 4\n",
      "repaglinide : 4\n",
      "glimepiride : 4\n",
      "glipizide : 4\n",
      "glyburide : 4\n",
      "pioglitazone : 4\n",
      "rosiglitazone : 4\n",
      "insulin : 4\n",
      "2nd_diag : 390\n",
      "3rd_diag : 425\n",
      "ai_response : 6802\n"
     ]
    }
   ],
   "source": [
    "EncCat_full_train_data = full_train_data[full_train_data.dtypes[full_train_data.dtypes == \"object\"].index[0:25]].copy()\n",
    "\n",
    "for col in EncCat_full_train_data.columns:\n",
    "    oneHotCols = 0\n",
    "    print(col,\":\", len(EncCat_full_train_data[col].unique()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'examide'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [889]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mfull_train_data\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexamide\u001B[49m\u001B[38;5;241m.\u001B[39mvalue_counts()\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5575\u001B[0m, in \u001B[0;36mNDFrame.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   5568\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   5569\u001B[0m     name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_internal_names_set\n\u001B[0;32m   5570\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_metadata\n\u001B[0;32m   5571\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_accessors\n\u001B[0;32m   5572\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_info_axis\u001B[38;5;241m.\u001B[39m_can_hold_identifiers_and_holds_name(name)\n\u001B[0;32m   5573\u001B[0m ):\n\u001B[0;32m   5574\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m[name]\n\u001B[1;32m-> 5575\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mobject\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__getattribute__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'DataFrame' object has no attribute 'examide'"
     ]
    }
   ],
   "source": [
    "full_train_data.examide.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ohe = skl.preprocessing.OneHotEncoder()\n",
    "EncCat_full_train_data_matrix = ohe.fit_transform(EncCat_full_train_data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "EncCat_full_train_data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Pre-processed numerical data appropriately including handling missing data and\n",
    "justified methods used. Note this may be different for each algorithm you try. [10 pts]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "id": "b7ca172bbb4ce1ec"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We already confirmed above that there are no NAs in our continuous data, so no need to impute."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I choose to scale the numeric columns for use in my RF and NN models."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = skl.preprocessing.StandardScaler()\n",
    "#Create new df for scaled numeric data\n",
    "scaledNum_full_train_data = full_train_data[full_train_data.dtypes[full_train_data.dtypes == \"int64\"].index[1:6]].copy()\n",
    "numeric_columns = list(full_train_data.dtypes[full_train_data.dtypes == \"int64\"].index)[0:6]\n",
    "\n",
    "# I use a for loop to quickly transform all numeric columns\n",
    "for column in numeric_columns:\n",
    "    transformed_column = scaler.fit_transform(np.array(full_train_data[column]).reshape(-1,1))\n",
    "    scaledNum_full_train_data[column] = transformed_column"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "e61e88d828182f6f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.pairplot(full_train_data[['num_lab_procedures', 'num_procedures',\"number_outpatient\", 'number_emergency', 'number_diagnoses', 'num_medications']])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Implement a model to make predictions using text data using tf-idf [20 pts]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "id": "a26afb0df2f7ec5f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "48ef9f4d7317344f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. Use model stacking to incorporate tf-idf predictions for the text field\n",
    "(diag_desc_combined) in the downstream algorithm [20 pts]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "id": "e6ceeb5497e17e6a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "35916dd62fb0a7a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "6. Perform experimentation for multiple modeling algorithms and justify why you\n",
    "selected the experiments you chose [20 pts]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "id": "3cfebd359e05792c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "2e51699c682f0dfc",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "7. Final model selection and discussion of your model choice and the model weaknesses\n",
    "(generally, where model doesn’t perform well, etc.) [10 pts]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "id": "f62c39d7b40d7ac1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "5df1e27c507c597e",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part B: Model Performance (100 pts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "id": "7ebe1732de251b8b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Achieve AUC >= .675"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "id": "e6c048fd46211b5c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "21820e8d9db9332b",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}