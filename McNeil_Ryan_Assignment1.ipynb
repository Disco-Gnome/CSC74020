{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Setup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from math import *\n",
    "from decimal import Decimal"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Part A: Model Code (60 pts)\n",
    "1. Write a function to calculate and return the Minkowski distance with optional argument p\n",
    "defaulting to ‘p=2’ (Euclidean) of two vectors where a vector represents a data point.[6 pts]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.449\n"
     ]
    }
   ],
   "source": [
    "# Helper function - calculate distance value to given root value\n",
    "# ('p' is root value)\n",
    "# I'm going to name all of my custom functions starting with \"custom_\" so as not to\n",
    "# confuse them with the SciPy versions of these functions later.\n",
    "\n",
    "def p_root(value, root):\n",
    "    root_value = 1 / float(root)\n",
    "    return round (Decimal(value) **\n",
    "                  Decimal(root_value), 3)\n",
    "\n",
    "# Minkowski distance function using helper\n",
    "def custom_minkowski_distance(x_vector, y_vector, p_value = 2):\n",
    "    # Parallel calculation of p_values\n",
    "    return (p_root(sum(pow(abs(a-b), p_value)\n",
    "                       for a, b in zip(x_vector, y_vector)), p_value))\n",
    "\n",
    "# test execution\n",
    "vector1 = [0, 1, 2, 4]\n",
    "vector2 = [1, 3, 2, 5]\n",
    "print(custom_minkowski_distance(vector1, vector2))\n",
    "del(vector1, vector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Write a function to calculate and return the accuracy of two vectors. [4 pts]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.5\n"
     ]
    }
   ],
   "source": [
    "def custom_accuracy(y_vals, y_preds):\n",
    "    true_predictions = 0\n",
    "    for i in range(len(y_vals)):\n",
    "        if y_preds[i] == y_vals[i]:\n",
    "            true_predictions += 1\n",
    "    acc_val = true_predictions / len(y_vals)\n",
    "    return acc_val\n",
    "\n",
    "# test execution\n",
    "y_vals_input = [0,0,0,0,0,1,1,1,1,1]\n",
    "y_preds_input = [0,0,0,1,1,0,0,0,1,1]\n",
    "#TP: 2\n",
    "#FP: 2\n",
    "#TN: 3\n",
    "#FN: 3\n",
    "print(\"Accuracy score: \", custom_accuracy(y_vals_input, y_preds_input))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Write three functions to compute: precision, recall and F1 score. [6 pts]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score:  0.5\n",
      "Recall score:  0.4\n",
      "F1 score:  0.571\n"
     ]
    }
   ],
   "source": [
    "#Precision: TruePos / (TruePos + FalsePos)\n",
    "def custom_precision(y_vals, y_preds):\n",
    "    if y_preds.count(1) == 0:\n",
    "        raise Exception(\"Cannot calculate precision value: No predicted positives.\")\n",
    "    else:\n",
    "        TruePos = 0\n",
    "        FalsePos = 0\n",
    "        for i in range(len(y_vals)):\n",
    "            if y_preds[i] == 1:\n",
    "                if y_vals[i] == 1: TruePos += 1\n",
    "                if y_vals[i] == 0: FalsePos += 1\n",
    "        prec_score = TruePos / y_preds.count(1)\n",
    "    return round(prec_score, 3)\n",
    "\n",
    "# Recall: TruePos / (TruePos + FalseNeg)\n",
    "def custom_recall(y_vals, y_preds):\n",
    "    TruePos = 0\n",
    "    FalseNeg = 0\n",
    "    for i in range(len(y_vals)):\n",
    "        if y_vals[i] == 1:\n",
    "            if y_preds[i] == 1: TruePos += 1\n",
    "            if y_preds[i] == 0: FalseNeg += 1\n",
    "    if y_vals.count(1) == 0:\n",
    "        Exception(\"Cannot calculate recall: No real positives.\")\n",
    "    else:\n",
    "        recall_score = TruePos / (TruePos + FalseNeg)\n",
    "    return round(recall_score, 3)\n",
    "\n",
    "# F1: TruePos / (TruePos + 0.5(FalsePos + FalseNeg))\n",
    "def custom_F1_score(y_vals, y_preds):\n",
    "    TruePos = 0\n",
    "    FalsePos = 0\n",
    "    FalseNeg = 0\n",
    "    for i in range(len(y_vals)):\n",
    "        if y_vals[i] == 1:\n",
    "            if y_preds[i] == 1: TruePos += 1\n",
    "            if y_preds[i] == 0: FalseNeg += 1\n",
    "        else:\n",
    "            if y_preds == 1: FalsePos += 1\n",
    "    F1_val = TruePos / (TruePos + (FalsePos + FalseNeg)/2)\n",
    "    return round(F1_val, 3)\n",
    "\n",
    "print(\"Precision score: \", custom_precision(y_vals_input, y_preds_input))\n",
    "print(\"Recall score: \", custom_recall(y_vals_input, y_preds_input))\n",
    "print(\"F1 score: \", custom_F1_score(y_vals_input, y_preds_input))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Write a function to compute the confusion matrix of two vectors. [4 pts]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "                    Actual Positive  Actual Negative\nPredicted Positive                2                2\nPredicted Negative                3                3",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Actual Positive</th>\n      <th>Actual Negative</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Predicted Positive</th>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>Predicted Negative</th>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def custom_confusion_matrix(y_vals, y_preds):\n",
    "    TruePos = 0\n",
    "    FalsePos = 0\n",
    "    TrueNeg = 0\n",
    "    FalseNeg = 0\n",
    "    for i in range(len(y_vals)):\n",
    "        if y_vals[i] == 1:\n",
    "            if y_preds[i] == 1: TruePos += 1\n",
    "            if y_preds[i] == 0: FalseNeg += 1\n",
    "        else:\n",
    "            if y_preds[i] == 1: FalsePos += 1\n",
    "            if y_preds[i] == 0: TrueNeg +=1\n",
    "    conf_mtrx = pd.DataFrame([[TruePos, FalsePos],[TrueNeg,FalseNeg]],\n",
    "                             index = [\"Predicted Positive\",\"Predicted Negative\"],\n",
    "                             columns = [\"Actual Positive\", \"Actual Negative\"])\n",
    "    return conf_mtrx\n",
    "\n",
    "custom_confusion_matrix(y_vals_input, y_preds_input)\n",
    "# With test vectors, should be:\n",
    "# TP: 2 ; FP: 2\n",
    "# TN: 3 ; FN: 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. Write a function to generate the Receiver Operating Characteristic (ROC) curve. [5 pts]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "6. Write a function to compute area under curve (AUC) for the ROC curve. [5 pts]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "7. Write a function to generate the precision-recall curve. [5 pts]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "8. Implement a KNN_Classifier model class. It should have the following three methods. [20\n",
    "pts]\n",
    "a) __init__(self,) It’s a standard python initialization function so we can instantiate the\n",
    "class. Just “pass” this. [5 pts]\n",
    "Arguments:\n",
    "n_neighbors : int, optional (default = 5) The number of nearest neighbors.\n",
    "weights : string, optional (default = ‘uniform’) The weight function used in prediction.\n",
    "Possible values:\n",
    "- ‘uniform’: uniform weights. All points in each neighborhood are weighted\n",
    "equally.\n",
    "- ‘distance’: weight points by the inverse of their distance. in this case, closer\n",
    "neighbors of a query point will have a greater influence than neighbors which are\n",
    "further away\n",
    "p: int, optional (default = 2) Minkowski distance.\n",
    "Returns: No return value necessary."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "b) fit(self, X, Y) This method simply needs to store the relevant values as instance\n",
    "variables. [5 pts]\n",
    "Arguments:\n",
    "X : ndarray A numpy array with rows representing data samples and columns representing\n",
    "features.\n",
    "Y : ndarray A 1D numpy array with labels corresponding to each row of the feature matrix X.\n",
    "Returns: No return value necessary."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "c) predict(self, X,threshold=.5) This method will use the instance variables stored by the fit\n",
    "method. [2 pts] Arguments:\n",
    "X : ndarray A numpy array containing samples to be used for prediction. Its rows represent data\n",
    "samples and columns represent features.\n",
    "Returns: 1D array of class labels for each row in X. The 1D array should be designed as a\n",
    "column vector. Hint: you can just have this call predict_proba(...) and use threshold after"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "d) predict_proba(self, X) Same as c) but for probabilities [3 pts] Arguments:\n",
    "X : ndarray A numpy array containing samples to be used for prediction. Its rows represent data\n",
    "samples and columns represent features.\n",
    "Returns: 1D array of prediction probabilities for positive class for each row in X. The 1D\n",
    "array should be designed as a column vector."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "e) get_params(self) Get parameters for this estimator. [3 pts]\n",
    "Arguments: N/A\n",
    "Returns: dict Model parameter names mapped to their values."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "f) set_params(self, **params) [2 pts] Arguments:\n",
    "**params : dict A dictionary with the model parameter names to change mapped to their values\n",
    "Returns: No return value necessary."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "9. Write a function named “partition” to split your data into training and test sets. The function\n",
    "should take 4 arguments: [ 5 pts]\n",
    "• feature matrix (numpy array with rows representing data samples and columns\n",
    "representing features.),\n",
    "• target vector (numpy array with labels corresponding to each row of the feature\n",
    "matrix),\n",
    "• t where t is a real number to determine the size of partition. For example, if t is set to\n",
    "0.2, then 80% of the data will be used for training and 20% for testing.\n",
    "• shuffle (default=True) where shuffle is a boolean whether to shuffle the data prior to\n",
    "partitioning. You will be required to use “shuffle=True” for this assignment\n",
    "• This function should return two feature matrices for training and test data, and two\n",
    "target vectors for training and test data (4 tuple)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Part B: Data Processing, Feature Selection, and Initial Estimation (40 pts)\n",
    "10. Read in the winequality-white.csv file as a Pandas data frame."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "11. The target will be the “quality” column which represents the rating of wine and ranges from\n",
    "3 to 8. You will need to convert it into a two-category variable consisting of “good” (quality\n",
    "> 5) & “bad” (quality <= 5). Your target vector should have 0s (representing “bad” quality\n",
    "wine) and 1s (representing “good” quality wine). [2 pts]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "12. Provide a table with univariate statistics of your data (mean, standard deviation, and\n",
    "quartiles, min, max, missing count, number of unique values). [4 pts]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "13. Generate pair plots using the seaborn package to help identify redundant features. For any\n",
    "redundant features(?), report, drop, and explain your logic (w/ markdown). [4 pts]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "14. Use your “partition” function to split the data into 80% train and 20% test. [5 pts]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "15. Naively run your KNN_Classifier model on the training dataset with n_neighbors = 5 and\n",
    "using Euclidean distance. [15 pts]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "a. Use accuracy and F1 score to compare your predictions to the expected labels."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "b. Now standardize each feature of your training set (subtract mean and divide by\n",
    "standard deviation) and apply trained standardization to the test set. Use the mean\n",
    "and standard deviation values for each feature in the training set to scale the test\n",
    "data (you can use sklearn.preprocessing.StandardScaler)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "c. Re-run the KNN_Classifier model on the standardized data, find the accuracy and F1\n",
    "score with the expected labels."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "d. Compare the two accuracy values and the F1 scores; and decide whether you should\n",
    "use standardized data or unscaled data for the remainder of the assignment."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "e. Perform a similar test for inverse distance weighting in the KNN_Classifier model\n",
    "and determine whether or not to use it. [5 pts]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "16. Repeat #15 a-d, but using a logistic regression with ‘elasticnet’ or ‘l2’ penalty (feel free to\n",
    "use sklearn.linear_model.LogisticRegression) [10 pts]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Part C: Model Evaluation and Results Summary (100 pts)\n",
    "17) Evaluation of an estimator performance via cross-validation: Implement the S-fold cross\n",
    "validation function. [15 pts]\n",
    "a. sFold(folds, data, labels, model, model_args, error_fuction)\n",
    "    i. folds is an integer number of folds.\n",
    "    ii. data is a numpy array with rows representing data samples and columns\n",
    "representing features.\n",
    "    iii. labels is a numpy array with labels corresponding to each row of\n",
    "training_features.\n",
    "    iv. model is an object with the fit and predict methods.\n",
    "    v. model args is a dictionary of arguments to pass to the classification algorithm. If\n",
    "you are unfamiliar, look up using the ** operator to unpack dictionaries as\n",
    "arguments\n",
    "    vi. error_function :Returns error value between predicted and true labels. For\n",
    "example, mean squared error (mse) function could be used as error_function.\n",
    "b. How it should work:\n",
    "    i. Use a helper function to calculate an s-partition of the data (i.e., partition the data into s\n",
    "equally sized portions). You may use sklearn.model_selection.KFold if you wish and\n",
    "assume data is already shuffled.\n",
    "    ii. For each partition\n",
    "        a. Make a model using the model class\n",
    "        b. Fit the data to all other partitions (1 – folds)\n",
    "        c. Make prediction on current partition\n",
    "        d. Store expected labels and predicted labels for current partition\n",
    "    iii. Calculate the average error (for all partitions) using the error_function on stored\n",
    "expected and predicted labels\n",
    "c. It should return a Python tuple with the following\n",
    "    i. Expected labels\n",
    "    ii. Predicted labels\n",
    "    iii. Average error"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "18) Only using the training portion of your data, use your sfold function to evaluate the\n",
    "performance of your model over each combination of k and distance metrics from the following\n",
    "sets: [10 pts]\n",
    "i. k=[1,5,9,11]\n",
    "b. distance = [Euclidean, Manhattan]\n",
    "ii. weights = [uniform, distance]\n",
    "iii. From the returned tuple store as a row in a pandas DataFrame with headers:\n",
    "Experiment name, k, distance, weights, Average F1\n",
    "iv. Determine the best model based on the overall performance. For the error_function\n",
    "of the S-fold function argument use the F1 score function from Part A."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "19) Repeat #18 for at least 3 experiments for the regularized logistic regression from #16\n",
    "and discuss why you optimized over your selected hyper-parameters [10 pts]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "20) Based on the results above, use the full training portion (80%), to re-estimate your best\n",
    "(subjective) model. Discuss why you made your choice. [5 pts]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "21) Evaluate your best model on the test data and report the performance measures.[10 pts]\n",
    "i. Precision\n",
    "ii. Recall\n",
    "iii. F1 score\n",
    "iv. Confusion matrix\n",
    "v. Accuracy & Generalization Error"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "22) Generate the ROC curve and determine the optimal threshold that maximizes the F1 score.\n",
    "[10 pts] Note: for F1, you can iterate through possible thresholds and check F1 for each."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "23) Compute the AUC score. [5 pts]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "24) Generate the precision-recall curve and determine the optimal threshold (visually). [5 pts]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "25) Calculate and report the 95% confidence interval on the generalization error estimate. [5pts]\n",
    "2 possible options (others as well):\n",
    "1. Use the s fold accuracy scores (score for each fold) and take the standard deviation, then\n",
    "subtracting/adding from the average, 1.96 (95% confidence interval) times the std dev\n",
    "2. Use the following: Accuracy +/- 1.96 * sqrt( (accuracy * (1 - accuracy)) / n)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "26) Write a “Summary and Methods” section. [10 pts] No more than 2-5 sentences for each\n",
    "question below:\n",
    "i. Provide a summary of the project and what you completed in the assignment.\n",
    "ii. Describe the dataset and features. What is the target? What are you calculating it from?\n",
    "iii. Describe the differences in fit and predict between the regularized logistic regression vs\n",
    "KNN_Classifier. In particular, discuss training time vs prediction time for large data.\n",
    "Also discuss the hyperparameters of each and why they are used."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "27) Write a “Results” section. [15 pts] No more than 2-5 sentences for each question below\n",
    "a) Describe the performance of the KNN model with respect to the different levels of k\n",
    "and the different distance metrics. Include a table of performances, bolding the best.\n",
    "b) Characterize the overall performance of your model.\n",
    "c) Discuss which quality values (original rating) led to good performance of your model\n",
    "and those that resulted in poor performance. Include a table of average error (e.g., F1\n",
    "score) to support your claims.\n",
    "d) Give any final conclusions."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}